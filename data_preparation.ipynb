{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to prepare the data for machine learning.\n",
    "\n",
    "1. Annotate the dataset (Sleep 0 /Awake 1)\n",
    "2. Signal Preparation (scaling, missing data, outliers, smoothing)\n",
    "3. Subset generation (light, medium, heavy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert timestamp to datetime**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = [\n",
    "    pl.col(\"timestamp\").str.to_datetime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert angle to radians**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deg_to_rad(x: pl.Expr) -> pl.Expr:\n",
    "    return np.pi / 180 * x\n",
    "\n",
    "angleConversion = [\n",
    "    deg_to_rad(pl.col(\"anglez\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Min-max normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_normalization = lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "normalization = [\n",
    "    pl.col(\"anglez\").map_batches(min_max_normalization).cast(pl.Float32), \n",
    "    pl.col(\"enmo\").map_batches(min_max_normalization).cast(pl.Float32),\n",
    "    pl.col(\"step\").cast(pl.UInt32),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signals = pl.scan_parquet(\"data/train_series.parquet\").with_columns(\n",
    "    timestamp + angleConversion + normalization\n",
    ").collect(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = pl.scan_csv(\"data/train_events.csv\").with_columns(\n",
    "    timestamp + [pl.col(\"step\").cast(pl.UInt32)]\n",
    ").drop_nulls().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mismatch Onset and Wakeup are : \n",
      " shape: (5, 2)\n",
      "┌──────────────┬───────┐\n",
      "│ series_id    ┆ night │\n",
      "│ ---          ┆ ---   │\n",
      "│ str          ┆ i64   │\n",
      "╞══════════════╪═══════╡\n",
      "│ 0ce74d6d2106 ┆ 20    │\n",
      "│ 154fe824ed87 ┆ 30    │\n",
      "│ 44a41bba1ee7 ┆ 10    │\n",
      "│ efbfc4526d58 ┆ 7     │\n",
      "│ f8a8da8bdd00 ┆ 17    │\n",
      "└──────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Removing null events and nights with mismatched counts from series_events\n",
    "mismatches = df_events.group_by(['series_id', 'night']).agg(\n",
    "    (pl.col('event') == 'onset').sum().alias('onset'),\n",
    "    (pl.col('event') == 'wakeup').sum().alias('wakeup')\n",
    "    ).sort(by=['series_id', 'night']).filter(pl.col('onset') != pl.col('wakeup')).select(pl.all().exclude('onset', 'wakeup'))\n",
    "print(f\"The mismatch Onset and Wakeup are : \\n {mismatches}\")\n",
    "df_events = df_events.join(mismatches, on=['series_id', 'night'], how='anti')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count for each series_id the number of onset and wakeup events\n",
    "df_events_problem = df_events.group_by(['series_id']).agg(\n",
    "    (pl.col('event') == 'onset').sum().alias('onset'),\n",
    "    (pl.col('event') == 'wakeup').sum().alias('wakeup')\n",
    "    ).sort(by=['series_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mismatch Onset and Wakeup are : \n",
      " shape: (0, 1)\n",
      "┌───────────┐\n",
      "│ series_id │\n",
      "│ ---       │\n",
      "│ str       │\n",
      "╞═══════════╡\n",
      "└───────────┘\n"
     ]
    }
   ],
   "source": [
    "# display the series_id with mismatched counts\n",
    "mismatches = df_events_problem.filter(pl.col('onset') != pl.col('wakeup')).select(pl.all().exclude('onset', 'wakeup'))\n",
    "print(f\"The mismatch Onset and Wakeup are : \\n {mismatches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_signals.join_asof(\n",
    "        df_events.drop('timestamp'),\n",
    "        on='step',\n",
    "        by='series_id',\n",
    "        strategy='backward',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Annotation Sleep // Awake**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "        state= pl.when((pl.col('event')=='onset')).then(1).otherwise(0),\n",
    "    ).select(\n",
    "        pl.all().exclude('event','night')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.with_columns(\n",
    "        delta = pl.col('state').shift(-1) - pl.col('state'),\n",
    "    ).with_columns(\n",
    "        wakeup = pl.when(pl.col('delta') == -1).then(True).otherwise(False),\n",
    "        onset = pl.when(pl.col('delta') == 1).then(True).otherwise(False),\n",
    "    )\n",
    ").drop('delta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort(by=['series_id', 'timestamp'])\n",
    "df = df.drop('step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Data**\n",
    "\n",
    "Remove signals 6 hours after awake and 6 hours before sleep when an annotation is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each parquet file representing a time series\n",
    "# We will sort them by timestamp\n",
    "# if there are periods with 20 hours without sleep\n",
    "# We will remove a period of 16 hours because we consider the annotations as missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_train_dataset(train_data, train_events, drop_nulls=False) :\n",
    "    \n",
    "#     series_ids = train_data['series_id'].unique(maintain_order=True).to_list()\n",
    "#     X, y = pl.DataFrame(), pl.DataFrame()\n",
    "#     for idx in tqdm(series_ids) : \n",
    "        \n",
    "#         # Normalizing sample features\n",
    "#         sample = train_data.filter(pl.col('series_id')==idx).with_columns(\n",
    "#             [(pl.col(col) / pl.col(col).std()).cast(pl.Float32) for col in feature_cols if col != 'hour']\n",
    "#         )\n",
    "        \n",
    "#         events = train_events.filter(pl.col('series_id')==idx)\n",
    "        \n",
    "#         if drop_nulls : \n",
    "#             # Removing datapoints on dates where no data was recorded\n",
    "#             sample = sample.filter(\n",
    "#                 pl.col('timestamp').dt.date().is_in(events['timestamp'].dt.date())\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smoothing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.group_by('series_id').agg(pl.count().alias('count')).sort(by='count', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow = df.filter(\n",
    "    pl.col('series_id') == '78569a801a38'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow.write_parquet('data/78569a801a38.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stratified Export**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
