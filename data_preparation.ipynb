{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to prepare the data for machine learning.\n",
    "\n",
    "1. Annotate the dataset (Sleep 0 /Awake 1)\n",
    "2. Signal Preparation (scaling, missing data, outliers, smoothing)\n",
    "3. Subset generation (light, medium, heavy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert timestamp to datetime**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = [\n",
    "    pl.col(\"timestamp\").str.to_datetime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Min-max normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_normalization = lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "normalization = [\n",
    "    pl.col(\"anglez\").map_batches(min_max_normalization).cast(pl.Float32), \n",
    "    pl.col(\"enmo\").map_batches(min_max_normalization).cast(pl.Float32),\n",
    "    pl.col(\"step\").cast(pl.UInt32),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signals = pl.scan_parquet(\"data/train_series.parquet\").with_columns(\n",
    "    timestamp + normalization\n",
    ").collect(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = pl.scan_csv(\"data/train_events.csv\").with_columns(\n",
    "    timestamp + [pl.col(\"step\").cast(pl.UInt32)]\n",
    ").drop_nulls().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mismatch Onset and Wakeup are : \n",
      " shape: (5, 2)\n",
      "┌──────────────┬───────┐\n",
      "│ series_id    ┆ night │\n",
      "│ ---          ┆ ---   │\n",
      "│ str          ┆ i64   │\n",
      "╞══════════════╪═══════╡\n",
      "│ 0ce74d6d2106 ┆ 20    │\n",
      "│ 154fe824ed87 ┆ 30    │\n",
      "│ 44a41bba1ee7 ┆ 10    │\n",
      "│ efbfc4526d58 ┆ 7     │\n",
      "│ f8a8da8bdd00 ┆ 17    │\n",
      "└──────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Removing null events and nights with mismatched counts from series_events\n",
    "mismatches = df_events.group_by(['series_id', 'night']).agg(\n",
    "    (pl.col('event') == 'onset').sum().alias('onset'),\n",
    "    (pl.col('event') == 'wakeup').sum().alias('wakeup')\n",
    "    ).sort(by=['series_id', 'night']).filter(pl.col('onset') != pl.col('wakeup')).select(pl.all().exclude('onset', 'wakeup'))\n",
    "print(f\"The mismatch Onset and Wakeup are : \\n {mismatches}\")\n",
    "df_events = df_events.join(mismatches, on=['series_id', 'night'], how='anti')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 5)\n",
      "┌──────────────┬───────┬────────┬───────┬─────────────────────────┐\n",
      "│ series_id    ┆ night ┆ event  ┆ step  ┆ timestamp               │\n",
      "│ ---          ┆ ---   ┆ ---    ┆ ---   ┆ ---                     │\n",
      "│ str          ┆ i64   ┆ str    ┆ u32   ┆ datetime[μs, UTC]       │\n",
      "╞══════════════╪═══════╪════════╪═══════╪═════════════════════════╡\n",
      "│ 038441c925bb ┆ 1     ┆ onset  ┆ 4992  ┆ 2018-08-15 02:26:00 UTC │\n",
      "│ 038441c925bb ┆ 1     ┆ wakeup ┆ 10932 ┆ 2018-08-15 10:41:00 UTC │\n",
      "│ 038441c925bb ┆ 2     ┆ onset  ┆ 20244 ┆ 2018-08-15 23:37:00 UTC │\n",
      "│ 038441c925bb ┆ 2     ┆ wakeup ┆ 27492 ┆ 2018-08-16 09:41:00 UTC │\n",
      "│ …            ┆ …     ┆ …      ┆ …     ┆ …                       │\n",
      "│ 038441c925bb ┆ 4     ┆ onset  ┆ 57240 ┆ 2018-08-18 03:00:00 UTC │\n",
      "│ 038441c925bb ┆ 4     ┆ wakeup ┆ 62856 ┆ 2018-08-18 10:48:00 UTC │\n",
      "│ 038441c925bb ┆ 6     ┆ onset  ┆ 91296 ┆ 2018-08-20 02:18:00 UTC │\n",
      "│ 038441c925bb ┆ 6     ┆ wakeup ┆ 97860 ┆ 2018-08-20 11:25:00 UTC │\n",
      "└──────────────┴───────┴────────┴───────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df_events.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count for each series_id the number of onset and wakeup events\n",
    "df_events_problem = df_events.group_by(['series_id']).agg(\n",
    "    (pl.col('event') == 'onset').sum().alias('onset'),\n",
    "    (pl.col('event') == 'wakeup').sum().alias('wakeup')\n",
    "    ).sort(by=['series_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mismatch Onset and Wakeup are : \n",
      " shape: (0, 1)\n",
      "┌───────────┐\n",
      "│ series_id │\n",
      "│ ---       │\n",
      "│ str       │\n",
      "╞═══════════╡\n",
      "└───────────┘\n"
     ]
    }
   ],
   "source": [
    "# display the series_id with mismatched counts\n",
    "mismatches = df_events_problem.filter(pl.col('onset') != pl.col('wakeup')).select(pl.all().exclude('onset', 'wakeup'))\n",
    "print(f\"The mismatch Onset and Wakeup are : \\n {mismatches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_signals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_355612/102231499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = df_signals.join_asof(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mdf_events\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'series_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'backward'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_signals' is not defined"
     ]
    }
   ],
   "source": [
    "df = df_signals.join_asof(\n",
    "        df_events,\n",
    "        on='step',\n",
    "        by='series_id',\n",
    "        strategy='backward',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Annotation Sleep // Awake**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_355612/1996925032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = df.with_columns(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'event'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'wakeup'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0motherwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df.with_columns(\n",
    "    state= pl.when((pl.col('event')=='wakeup')).then(True).otherwise(False).cast(pl.Boolean)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Data**\n",
    "\n",
    "Remove signals 6 hours after awake and 6 hours before sleep when an annotation is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each parquet file representing a time series\n",
    "# We will sort them by timestamp\n",
    "# if there are periods with 20 hours without sleep\n",
    "# We will remove a period of 16 hours because we consider the annotations as missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smoothing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stratified Export**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
