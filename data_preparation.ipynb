{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to prepare the data for machine learning.\n",
    "\n",
    "1. Annotate the dataset (Sleep 0 /Awake 1)\n",
    "2. Signal Preparation (scaling, missing data, outliers, smoothing)\n",
    "3. Subset generation (light, medium, heavy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "import gc\n",
    "import joblib\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert timestamp to datetime**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = [\n",
    "    pl.col(\"timestamp\").str.to_datetime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Min-max normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_normalization = lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "normalization = [\n",
    "    pl.col(\"anglez\").map_batches(min_max_normalization).cast(pl.Float32), \n",
    "    pl.col(\"enmo\").map_batches(min_max_normalization).cast(pl.Float32),\n",
    "    pl.col(\"step\").cast(pl.UInt32),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signals = pl.scan_parquet(\"data/train_series.parquet\").with_columns(\n",
    "    timestamp + normalization\n",
    ").collect(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = pl.scan_csv(\"data/train_events.csv\").with_columns(\n",
    "    timestamp + [pl.col(\"step\").cast(pl.UInt32)]\n",
    ").drop_nulls().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Removing null events and nights with mismatched counts from series_events\\nmismatches = df_events.group_by([\\'series_id\\', \\'night\\']).agg(\\n    (pl.col(\\'event\\') == \\'onset\\').sum().alias(\\'onset\\'),\\n    (pl.col(\\'event\\') == \\'wakeup\\').sum().alias(\\'wakeup\\')\\n    ).sort(by=[\\'series_id\\', \\'night\\']).filter(pl.col(\\'onset\\') != pl.col(\\'wakeup\\')).select(pl.all().exclude(\\'onset\\', \\'wakeup\\'))\\nprint(f\"The mismatch Onset and Wakeup are : \\n {mismatches}\")\\ndf_events = df_events.join(mismatches, on=[\\'series_id\\', \\'night\\'], how=\\'anti\\')\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Removing null events and nights with mismatched counts from series_events\n",
    "mismatches = df_events.group_by(['series_id', 'night']).agg(\n",
    "    (pl.col('event') == 'onset').sum().alias('onset'),\n",
    "    (pl.col('event') == 'wakeup').sum().alias('wakeup')\n",
    "    ).sort(by=['series_id', 'night']).filter(pl.col('onset') != pl.col('wakeup')).select(pl.all().exclude('onset', 'wakeup'))\n",
    "print(f\"The mismatch Onset and Wakeup are : \\n {mismatches}\")\n",
    "df_events = df_events.join(mismatches, on=['series_id', 'night'], how='anti')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count for each series_id the number of onset and wakeup events\n",
    "df_events_problem = df_events.group_by(['series_id']).agg(\n",
    "    (pl.col('event') == 'onset').sum().alias('onset'),\n",
    "    (pl.col('event') == 'wakeup').sum().alias('wakeup')\n",
    "    ).sort(by=['series_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mismatch Onset and Wakeup are : \n",
      " shape: (5, 1)\n",
      "┌──────────────┐\n",
      "│ series_id    │\n",
      "│ ---          │\n",
      "│ str          │\n",
      "╞══════════════╡\n",
      "│ 0ce74d6d2106 │\n",
      "│ 154fe824ed87 │\n",
      "│ 44a41bba1ee7 │\n",
      "│ efbfc4526d58 │\n",
      "│ f8a8da8bdd00 │\n",
      "└──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# display the series_id with mismatched counts\n",
    "mismatches = df_events_problem.filter(pl.col('onset') != pl.col('wakeup')).select(pl.all().exclude('onset', 'wakeup'))\n",
    "print(f\"The mismatch Onset and Wakeup are : \\n {mismatches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_signals.join(df_events, on=['series_id', 'timestamp', 'step'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Annotation Sleep // Awake**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    pl.lit(False).alias('state').cast(pl.Boolean)\n",
    ")\n",
    "\n",
    "def compute_state(df_group: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Check if there are onset and wakeup events in the group, if not, return as it is\n",
    "    if not ('onset' in df_group['event'].unique() and 'wakeup' in df_group['event'].unique()):\n",
    "        return df_group.with_columns(pl.lit(True).alias('state'))\n",
    "    \n",
    "    # Find the step for onset and wakeup\n",
    "    onset_step = df_group.select('step', 'event').filter(pl.col('event') == 'onset')['step'][0]\n",
    "    wakeup_step = df_group.select('step', 'event').filter(pl.col('event') == 'wakeup')['step'][0]\n",
    "    #print(f\"onset_step: {onset_step}, wakeup_step: {wakeup_step}\")\n",
    "\n",
    "    # Create the state column based on the range\n",
    "    state_logic = (\n",
    "        pl.when(df_group['step'] < onset_step).then(True)\n",
    "        .when((df_group['step'] >= onset_step) & (df_group['step'] <= wakeup_step)).then(False)\n",
    "        .otherwise(True)\n",
    "    )\n",
    "    \n",
    "    df_group = df_group.with_columns(state_logic.alias('state'))\n",
    "    \n",
    "    return df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/277 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onset_step: 269976, wakeup_step: 273324\n",
      "onset_step: 7812, wakeup_step: 14844\n",
      "onset_step: 284472, wakeup_step: 291816\n",
      "onset_step: 301692, wakeup_step: 308184\n",
      "onset_step: 25596, wakeup_step: 33144\n",
      "onset_step: 42924, wakeup_step: 48780\n",
      "onset_step: 318852, wakeup_step: 325392\n",
      "onset_step: 59400, wakeup_step: 65016\n",
      "onset_step: 336312, wakeup_step: 342348\n",
      "onset_step: 77076, wakeup_step: 82572\n",
      "onset_step: 353112, wakeup_step: 359376\n",
      "onset_step: 94176, wakeup_step: 100428\n",
      "onset_step: 370260, wakeup_step: 375876\n",
      "onset_step: 386820, wakeup_step: 393300\n",
      "onset_step: 111492, wakeup_step: 117492\n",
      "onset_step: 146016, wakeup_step: 152172\n",
      "onset_step: 163656, wakeup_step: 169512\n",
      "onset_step: 180552, wakeup_step: 186660\n",
      "onset_step: 197112, wakeup_step: 205056\n",
      "onset_step: 215544, wakeup_step: 222012\n",
      "onset_step: 232020, wakeup_step: 238776\n",
      "onset_step: 249252, wakeup_step: 256860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/277 [00:03<08:22,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onset_step: 7836, wakeup_step: 14832\n",
      "onset_step: 25152, wakeup_step: 32160\n",
      "onset_step: 42384, wakeup_step: 49044\n",
      "onset_step: 59712, wakeup_step: 66420\n",
      "onset_step: 76404, wakeup_step: 83964\n",
      "onset_step: 94584, wakeup_step: 101244\n",
      "onset_step: 111672, wakeup_step: 118644\n",
      "onset_step: 128868, wakeup_step: 135756\n",
      "onset_step: 145776, wakeup_step: 152904\n",
      "onset_step: 163332, wakeup_step: 170364\n",
      "onset_step: 180756, wakeup_step: 187500\n",
      "onset_step: 198180, wakeup_step: 205284\n",
      "onset_step: 215352, wakeup_step: 222828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/277 [00:07<10:58,  2.40s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/olivier/Documents/projet/DetectSleepStates/data_preparation.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olivier/Documents/projet/DetectSleepStates/data_preparation.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m series_id \u001b[39min\u001b[39;00m tqdm(df[\u001b[39m'\u001b[39m\u001b[39mseries_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/olivier/Documents/projet/DetectSleepStates/data_preparation.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     df_serie \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mfilter(pl\u001b[39m.\u001b[39;49mcol(\u001b[39m'\u001b[39;49m\u001b[39mseries_id\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m==\u001b[39;49m series_id)\u001b[39m.\u001b[39mgroup_by([\u001b[39m'\u001b[39m\u001b[39mnight\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mmap_groups(compute_state)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olivier/Documents/projet/DetectSleepStates/data_preparation.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     df_serie\u001b[39m.\u001b[39mwrite_parquet(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/train_series/\u001b[39m\u001b[39m{\u001b[39;00mseries_id\u001b[39m}\u001b[39;00m\u001b[39m.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/polars/dataframe/frame.py:3998\u001b[0m, in \u001b[0;36mDataFrame.filter\u001b[0;34m(self, *predicates, **constraints)\u001b[0m\n\u001b[1;32m   3901\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfilter\u001b[39m(\n\u001b[1;32m   3902\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   3903\u001b[0m     \u001b[39m*\u001b[39mpredicates: (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3910\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconstraints: Any,\n\u001b[1;32m   3911\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   3912\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3913\u001b[0m \u001b[39m    Filter the rows in the DataFrame based on a predicate expression.\u001b[39;00m\n\u001b[1;32m   3914\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3996\u001b[0m \n\u001b[1;32m   3997\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3998\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlazy()\u001b[39m.\u001b[39;49mfilter(\u001b[39m*\u001b[39;49mpredicates, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconstraints)\u001b[39m.\u001b[39;49mcollect(_eager\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/polars/utils/deprecation.py:96\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs: P\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: P\u001b[39m.\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m     93\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     94\u001b[0m         old_name, new_name, kwargs, function\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, version\n\u001b[1;32m     95\u001b[0m     )\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/polars/lazyframe/frame.py:1787\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, no_optimization, streaming, _eager)\u001b[0m\n\u001b[1;32m   1774\u001b[0m     comm_subplan_elim \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m ldf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ldf\u001b[39m.\u001b[39moptimization_toggle(\n\u001b[1;32m   1777\u001b[0m     type_coercion,\n\u001b[1;32m   1778\u001b[0m     predicate_pushdown,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1785\u001b[0m     _eager,\n\u001b[1;32m   1786\u001b[0m )\n\u001b[0;32m-> 1787\u001b[0m \u001b[39mreturn\u001b[39;00m wrap_df(ldf\u001b[39m.\u001b[39;49mcollect())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for series_id in tqdm(df['series_id'].unique()):\n",
    "    df_serie = df.filter(pl.col('series_id') == series_id).group_by(['night']).map_groups(compute_state)\n",
    "    df_serie.write_parquet(f\"data/train_series/{series_id}.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Data**\n",
    "\n",
    "Remove signals 6 hours after awake and 6 hours before sleep when an annotation is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each parquet file representing a time series\n",
    "# We will sort them by timestamp\n",
    "# if there are periods with 20 hours without sleep\n",
    "# We will remove a period of 16 hours because we consider the annotations as missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smoothing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stratified Export**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
