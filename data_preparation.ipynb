{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to prepare the data for machine learning.\n",
    "\n",
    "1. Annotate the dataset (Sleep 0 /Awake 1)\n",
    "2. Signal Preparation (scaling, missing data, outliers, smoothing)\n",
    "3. Subset generation (light, medium, heavy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert timestamp to datetime**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = [\n",
    "    pl.col(\"timestamp\").str.to_datetime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Min-max normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_normalization = lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "normalization = [\n",
    "    pl.col(\"anglez\").map_batches(min_max_normalization).cast(pl.Float32), \n",
    "    pl.col(\"enmo\").map_batches(min_max_normalization).cast(pl.Float32),\n",
    "    pl.col(\"step\").cast(pl.UInt32),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signals = pl.scan_parquet(\"data/train_series.parquet\").with_columns(\n",
    "    timestamp + normalization\n",
    ").collect(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = pl.scan_csv(\"data/train_events.csv\").with_columns(\n",
    "    timestamp + [pl.col(\"step\").cast(pl.UInt32)]\n",
    ").drop_nulls().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mismatch Onset and Wakeup are : \n",
      " shape: (5, 2)\n",
      "┌──────────────┬───────┐\n",
      "│ series_id    ┆ night │\n",
      "│ ---          ┆ ---   │\n",
      "│ str          ┆ i64   │\n",
      "╞══════════════╪═══════╡\n",
      "│ 0ce74d6d2106 ┆ 20    │\n",
      "│ 154fe824ed87 ┆ 30    │\n",
      "│ 44a41bba1ee7 ┆ 10    │\n",
      "│ efbfc4526d58 ┆ 7     │\n",
      "│ f8a8da8bdd00 ┆ 17    │\n",
      "└──────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Removing null events and nights with mismatched counts from series_events\n",
    "mismatches = df_events.group_by(['series_id', 'night']).agg(\n",
    "    (pl.col('event') == 'onset').sum().alias('onset'),\n",
    "    (pl.col('event') == 'wakeup').sum().alias('wakeup')\n",
    "    ).sort(by=['series_id', 'night']).filter(pl.col('onset') != pl.col('wakeup')).select(pl.all().exclude('onset', 'wakeup'))\n",
    "print(f\"The mismatch Onset and Wakeup are : \\n {mismatches}\")\n",
    "df_events = df_events.join(mismatches, on=['series_id', 'night'], how='anti')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count for each series_id the number of onset and wakeup events\n",
    "df_events_problem = df_events.group_by(['series_id']).agg(\n",
    "    (pl.col('event') == 'onset').sum().alias('onset'),\n",
    "    (pl.col('event') == 'wakeup').sum().alias('wakeup')\n",
    "    ).sort(by=['series_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mismatch Onset and Wakeup are : \n",
      " shape: (0, 1)\n",
      "┌───────────┐\n",
      "│ series_id │\n",
      "│ ---       │\n",
      "│ str       │\n",
      "╞═══════════╡\n",
      "└───────────┘\n"
     ]
    }
   ],
   "source": [
    "# display the series_id with mismatched counts\n",
    "mismatches = df_events_problem.filter(pl.col('onset') != pl.col('wakeup')).select(pl.all().exclude('onset', 'wakeup'))\n",
    "print(f\"The mismatch Onset and Wakeup are : \\n {mismatches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_signals.join_asof(\n",
    "        df_events.drop('timestamp'),\n",
    "        on='step',\n",
    "        by='series_id',\n",
    "        strategy='backward',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Annotation Sleep // Awake**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "        state= pl.when((pl.col('event')=='onset')).then(1).otherwise(0),\n",
    "    ).select(\n",
    "        pl.all().exclude('event','night')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.with_columns(\n",
    "        delta = pl.col('state').shift(-1) - pl.col('state'),\n",
    "    ).with_columns(\n",
    "        wakeup = pl.when(pl.col('delta') == -1).then(True).otherwise(False),\n",
    "        onset = pl.when(pl.col('delta') == 1).then(True).otherwise(False),\n",
    "    )\n",
    ").drop('delta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Data**\n",
    "\n",
    "Remove signals 6 hours after awake and 6 hours before sleep when an annotation is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each parquet file representing a time series\n",
    "# We will sort them by timestamp\n",
    "# if there are periods with 20 hours without sleep\n",
    "# We will remove a period of 16 hours because we consider the annotations as missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_train_dataset(train_data, train_events, drop_nulls=False) :\n",
    "    \n",
    "#     series_ids = train_data['series_id'].unique(maintain_order=True).to_list()\n",
    "#     X, y = pl.DataFrame(), pl.DataFrame()\n",
    "#     for idx in tqdm(series_ids) : \n",
    "        \n",
    "#         # Normalizing sample features\n",
    "#         sample = train_data.filter(pl.col('series_id')==idx).with_columns(\n",
    "#             [(pl.col(col) / pl.col(col).std()).cast(pl.Float32) for col in feature_cols if col != 'hour']\n",
    "#         )\n",
    "        \n",
    "#         events = train_events.filter(pl.col('series_id')==idx)\n",
    "        \n",
    "#         if drop_nulls : \n",
    "#             # Removing datapoints on dates where no data was recorded\n",
    "#             sample = sample.filter(\n",
    "#                 pl.col('timestamp').dt.date().is_in(events['timestamp'].dt.date())\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smoothing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (277, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>series_id</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;78569a801a38&quot;</td><td>1433880</td></tr><tr><td>&quot;f564985ab692&quot;</td><td>1052820</td></tr><tr><td>&quot;fb223ed2278c&quot;</td><td>918360</td></tr><tr><td>&quot;f56824b503a0&quot;</td><td>846360</td></tr><tr><td>&quot;cfeb11428dd7&quot;</td><td>809820</td></tr><tr><td>&quot;062dbd4c95e6&quot;</td><td>778680</td></tr><tr><td>&quot;f0482490923c&quot;</td><td>761940</td></tr><tr><td>&quot;6ca4f4fca6a2&quot;</td><td>759240</td></tr><tr><td>&quot;d043c0ca71cd&quot;</td><td>745020</td></tr><tr><td>&quot;12d01911d509&quot;</td><td>744480</td></tr><tr><td>&quot;c107b5789660&quot;</td><td>740880</td></tr><tr><td>&quot;ebb6fae8ed43&quot;</td><td>737820</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;d515236bdeec&quot;</td><td>235620</td></tr><tr><td>&quot;83fa182bec3a&quot;</td><td>203760</td></tr><tr><td>&quot;99b829cbad2d&quot;</td><td>200880</td></tr><tr><td>&quot;9aed9ee12ae2&quot;</td><td>195840</td></tr><tr><td>&quot;a88088855de5&quot;</td><td>192780</td></tr><tr><td>&quot;a9e5f5314bcb&quot;</td><td>155160</td></tr><tr><td>&quot;5e816f11f5c3&quot;</td><td>136620</td></tr><tr><td>&quot;c535634d7dcd&quot;</td><td>136080</td></tr><tr><td>&quot;1c7c0bad1263&quot;</td><td>115380</td></tr><tr><td>&quot;60e51cad2ffb&quot;</td><td>113940</td></tr><tr><td>&quot;3a9a9dc2cbd9&quot;</td><td>103500</td></tr><tr><td>&quot;349c5562ee2c&quot;</td><td>37080</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (277, 2)\n",
       "┌──────────────┬─────────┐\n",
       "│ series_id    ┆ count   │\n",
       "│ ---          ┆ ---     │\n",
       "│ str          ┆ u32     │\n",
       "╞══════════════╪═════════╡\n",
       "│ 78569a801a38 ┆ 1433880 │\n",
       "│ f564985ab692 ┆ 1052820 │\n",
       "│ fb223ed2278c ┆ 918360  │\n",
       "│ f56824b503a0 ┆ 846360  │\n",
       "│ …            ┆ …       │\n",
       "│ 1c7c0bad1263 ┆ 115380  │\n",
       "│ 60e51cad2ffb ┆ 113940  │\n",
       "│ 3a9a9dc2cbd9 ┆ 103500  │\n",
       "│ 349c5562ee2c ┆ 37080   │\n",
       "└──────────────┴─────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.group_by('series_id').agg(pl.count().alias('count')).sort(by='count', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow = df.filter(\n",
    "    pl.col('series_id') == '78569a801a38'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow.write_parquet('data/78569a801a38.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stratified Export**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
